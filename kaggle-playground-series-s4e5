# %% [code]
---
title: "Flood prediction | Lightgbm TidyModels | R"
date: "2024-May-07"
output:
  html_document:
    toc: true
    toc_depth: 6
    code_folding: show
    theme: cosmo
    highlight: tango
editor_options:
  markdown:
    wrap: 72
  chunk_output_type: console
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      fig.align = "center",
                      fig.width = 7,
                      fig.height = 5)

```


## About the Data set:

Dataset Description

The dataset for this competition (both train and test) was generated from a deep learning model trained on the Flood Prediction Factors dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.

Files:

**train.csv** - the training dataset; FloodProbability is the target.
**test.csv** - the test dataset; your objective is to predict the FloodProbability for each row.
**sample_submission.csv** - a sample submission file in the correct formatrmat  


## Import libraries

```{r import-libraries}

library(tidyverse)
library(janitor)
library(scales)
library(GGally)
library(kableExtra)
library(ggcorrplot)
library(ggthemes)
library(ggridges)

# Model

library(tidymodels)
library(stacks)
library(doParallel)
library(bonsai)
library(finetune)
library(themis)
library(rlang)

theme_set(theme_light())
```

## Import data

```{r import-data}


flood_df_train <- read_csv("/kaggle/input/playground-series-s4e5/train.csv") %>% 
  clean_names() %>% 
  select(-id)

flood_df_test <- read_csv("/kaggle/input/playground-series-s4e5/test.csv") %>% 
  clean_names() %>% 
  select(-id)

sample_submission <- read_csv("/kaggle/input/playground-series-s4e5/sample_submission.csv")

```

## EDA

### Glimpse

```{r}


flood_df_train %>% 
  glimpse()

```


### New features

```{r}


men_act_feat = c(
  "monsoon_intensity",
  "topography_drainage",
  "river_management",
  "deforestation",
  "urbanization",
  "climate_change",
  "dams_quality",
  "siltation",
  "agricultural_practices",
  "encroachments",
  "ineffective_disaster_preparedness",
  "drainage_systems",
  "deteriorating_infrastructure",
  "population_score",
  "wetland_loss",
  "inadequate_planning",
  "political_factors"
)

natural_feat = c("coastal_vulnerability", "landslides", "watersheds")


flood_df_train_nf <- flood_df_train %>% 
  mutate(across(monsoon_intensity:political_factors, ~as.integer(.x)),
         v_sum = rowSums(select(., monsoon_intensity:political_factors)),
         humans_act = rowSums(select(., all_of(men_act_feat))),
         nature_feat = rowSums(select(., all_of(natural_feat))),
         humans_act_over_natural_feat = humans_act / nature_feat)


flood_df_test_nf <- flood_df_test %>% 
  mutate(across(monsoon_intensity:political_factors, ~as.integer(.x)),
         v_sum = rowSums(select(., monsoon_intensity:political_factors)),
         humans_act = rowSums(select(., all_of(men_act_feat))),
         nature_feat = rowSums(select(., all_of(natural_feat))),
         humans_act_over_natural_feat = humans_act / nature_feat)

new_features <- c("v_sum", "humans_act", "nature_feat", "humans_act_over_natural_feat" )


```


### Counts of distinct values

```{r}

map_df(flood_df_train_nf, n_distinct) %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "Counts of distinct values") %>%
  arrange(`Counts of distinct values`) %>% 
  kbl() %>%
  kable_classic(full_width = F)

```


### Counts of duplicated values

```{r}

map_df(flood_df_train_nf, function(x) sum(duplicated(x))) %>% 
pivot_longer(everything(),
               names_to = "Variable",
               values_to = "Counts of duplicated values") %>% 
   arrange(`Counts of duplicated values`) %>% 
                    kbl() %>% 
  kable_classic(full_width = F)

```


### Target Variable distribution


```{r, fig.width = 12, fig.height = 4}


flood_df_train %>% 
  select(flood_probability) %>% 
  ggplot(aes(x = flood_probability)) +
  geom_histogram(bins = 60, fill = "gray60", color = "white") +
  labs(title = "Target Variable distribution")



```


### Target variable distribution by Political factors

```{r}

flood_df_train %>%
  select(political_factors, flood_probability) %>%
  ggplot(aes(x = flood_probability, y = political_factors, group=political_factors, fill = political_factors)) +
  geom_boxplot(
    color = "gray80",
    outlier.colour = "darkred",
    show.legend = FALSE
  ) +
  scale_fill_gradient(low = "green", high = "darkred") +
  labs(title = "Target variable distribution by Political factors",
       x = "Flood probability",
       y = "Political factors")

```


### Correlation Matrix (Train Dataset)

```{r, fig.width=7, fig.height= 7, fig.align="center"}

tp_col = "#1D2671"
tn_col = "#C33764"

flood_df_train_nf %>%
  cor() %>%
  ggcorrplot(
    outline.col = "white",
    ggtheme = ggplot2::theme_minimal,
    colors = c(tn_col, "white", tp_col),
    tl.cex = 7,
    lab = TRUE,
    lab_size = 2,
    lab_col = "black",
    show.legend = TRUE
  ) +
  theme(
    plot.background = element_rect(fill = "#edf2f7", color = "white"),
    plot.title.position = "plot",
    plot.title = element_text(hjust = 0.5, size = 10)
  ) +
  labs(title = "Correlation Matrix (Train Dataset)")

```


```{r, fig.height= 10, fig.width= 10}

flood_df_train_nf %>%
  mutate(fp_bins = as.factor(if_else(
    flood_probability < 0.5, "below-0.5", "above-0.5"
  ))) %>%
  pivot_longer(-c(flood_probability, fp_bins),
               names_to = "variable",
               values_to = "value") %>%
  ggplot(aes(x = value, fill = fp_bins)) +
  geom_histogram( bins = 60) +
  scale_fill_manual(values = c("darkred", "orange2" )) +
  facet_wrap(vars(variable), 
             scales = "free", 
             ncol = 3) +
  guides(fill = guide_legend(ncol = 1))+
  theme_minimal() +
  theme(
    legend.position = "top",
    strip.background = element_rect(fill = "white"),
    strip.background.x = element_rect(colour = "white"),
    strip.background.y = element_rect(colour = "white"),
    strip.text = element_text(
      color = "black",
      face = "bold",
      size = 8
    ),
    axis.text.y = element_blank()
  )+
  labs(title = "Numeric Variables Distributions | Below-0.5 and Above-0.5",
       fill = "Flood Prob.",
       x = NULL,
       y = NULL
       )

```



### Ridge Plot 2% sample

```{r, fig.height= 12, fig.width= 10}

flood_df_train_nf %>% 
  select(-c(all_of(new_features))) %>% 
  group_by(flood_probability ) %>%
  slice_sample(prop = 0.02) %>%
  ungroup()  %>%
  pivot_longer(
    cols = -flood_probability,
    names_to = "variable",
    values_to = "values"
  ) %>%
  ggplot(aes(
    x = flood_probability,
    y = variable,
    height = values,
    fill = variable
  )) +
  geom_density_ridges(
    show.legend = FALSE,
    stat = "identity",
    scale = 2,
    alpha = 0.5,
    color = "white"
  ) +
  theme_bw() +
  scale_fill_manual(values = rep(c(
    "#005666", "#60BCC4", "#8E0000", "#F48B0B", "#11F6CD"
  ), 5)) +
  labs(
    title = "Ridge Plot 2% sample",
    x = NULL,
    y = NULL
  )


```

### Ridge Plot 2% sample | New features

```{r, fig.height= 6, fig.width= 6}

flood_df_train_nf %>% 
  select(all_of(new_features), flood_probability) %>% 
  group_by(flood_probability ) %>%
  slice_sample(prop = 0.02) %>%
  ungroup()  %>%
  pivot_longer(
    cols = -flood_probability,
    names_to = "variable",
    values_to = "values"
  ) %>%
  ggplot(aes(
    x = flood_probability,
    y = variable,
    height = values,
    fill = variable
  )) +
  geom_density_ridges(
    show.legend = FALSE,
    stat = "identity",
    scale = 2,
    alpha = 0.3,
    color = "white"
  ) +
  theme_bw() +
  scale_fill_manual(values = rep(c(
    "#005666", "#60BCC4", "#8E0000", "#F48B0B", "#11F6CD"
  ), 5)) +
  labs(
    title = "Ridge Plot 2% sample | New features",
    x = NULL,
    y = NULL
  )


```




# Model


## Data split

```{r Data-Split}


flood_df_train_for_model <- flood_df_train_nf %>% 
  group_by(flood_probability ) %>%
  slice_sample(prop = 0.5) %>%
  ungroup() 


seed = 27

set.seed(seed)


train_data <- flood_df_train_for_model


#### Generate CV samples 10 folds

set.seed(seed)
cv_fold <- vfold_cv (train_data, v = 10)
```





## Lightgbm model

```{r lightgbm-tune-grid }

lgbm_rec <-
  recipe(flood_probability ~ ., data = train_data) 


lgbm_spec <-
  boost_tree(
    trees = tune(),
    tree_depth = tune(),
    learn_rate = tune(),
    mtry = tune(),
    min_n = tune(),
    loss_reduction = tune()
  ) %>%
  set_engine(engine = "lightgbm",
             num_leaves = tune()
) %>%
  set_mode(mode = "regression")


### Create a workflow

lgbm_wf <- workflow() %>%
  add_recipe(lgbm_rec) %>%
  add_model(lgbm_spec)

lgbm_wf


set.seed(seed)

lgbm_ctrl <- control_grid(verbose = TRUE,
                        save_pred = TRUE,
                        save_workflow = TRUE)



params <- lgbm_wf %>%
  extract_parameter_set_dials() %>%
  update(trees = trees(range = c(800, 3000)),
         mtry = mtry(range = c(5, 20)),
         min_n = min_n(range = c(10, 30)),
         tree_depth = tree_depth(range = c(2, 17)),
         learn_rate = learn_rate(range = c(0.001, 0.01)),
         num_leaves = num_leaves(range = c(4, 50))
         ) %>%
  finalize(train_data)



lgbm_res <- tune_grid(
  lgbm_wf,
  resamples = cv_fold,
  grid = 30,
  control = lgbm_ctrl,
  metrics = metric_set(rmse),
  param_info = params
)

show_best(lgbm_res, metric = "rmse") %>% 
  kbl(format = "html", caption = "Lightgbm Best parameters | Tune Grid") %>%
  kable_classic(full_width = F)


```

```{r lightgbm-fine-tune}

set.seed(seed)

lgbm_sim_anneal <- tune_sim_anneal(
  lgbm_wf,
  resamples = cv_fold,
  iter = 5,
  initial = lgbm_res,
  control = control_sim_anneal(
    verbose = TRUE,
    verbose_iter = TRUE,
    save_pred = TRUE,
    save_workflow = TRUE
  ),
  metrics = metric_set(rmse),
  param_info = params
)


show_best(lgbm_sim_anneal, metric = "rmse") %>% 
  kbl(format = "html", caption = "Lightgbm Best parameters | Fine Tune") %>%
  kable_classic(full_width = F)


```



## Ensamble Stacking

```{r ensamble-stacking}

ensamble_stacking <- stacks() %>%  
  stacks::add_candidates(lgbm_sim_anneal) %>% 
  stacks::blend_predictions(
    penalty = c(10^seq(-4,-1,0.1)),,
    metric = metric_set(rmse),
    control = tune::control_grid(allow_par = TRUE)
  )

ensemble <- fit_members(ensamble_stacking)

```


### Submission

```{r Submission}

submit <- stacks::augment(ensemble, flood_df_test_nf) 


sample_submission %>%
  mutate(
    FloodProbability  = submit$.pred
  ) %>%
  write_csv("submission.csv")
```